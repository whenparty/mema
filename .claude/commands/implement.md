# Implement Task

## Input
$ARGUMENTS â€” task ID in format TASK-X.Y (e.g., TASK-1.1)

## Phase 0: Pick Up Task

Launch a **general-purpose** subagent (`Task` tool, `subagent_type: general-purpose`).
Pass it the task ID and instruct it to:

1. Search GitHub issues in `whenparty/mema` for "$ARGUMENTS" in title
2. Read the issue body â€” extract description, dependencies, traceability (FR/NFR/US refs)
3. Read `docs/specification/5_1_Backlog.md` â€” find the task, extract estimate/deps/traceability/labels
4. Check dependency issues â€” report which are open vs closed
5. Read `.claude/skills/specification-navigator/SKILL.md` first, then follow its reading
   strategy to find and read specification docs referenced in traceability.
   Summarize relevant requirements â€” do NOT return full doc text
6. Enrich the GitHub issue body by appending:
   ```
   ### Acceptance Criteria
   - [ ] [derived from FR/US/AC in spec docs]
   - [ ] [tests pass, typecheck clean, lint clean]

   ### Key Files
   - `src/path/to/file.ts` â€” [what it does]

   ### Spec References
   - [FR-MEM.1](docs/specification/3_1_Functional_Requirements.md) â€” [short description]
   ```
7. Read module AGENTS.md files for affected modules (if they exist)

The subagent returns a **task brief**:
```
Task: TASK-X.Y â€” [title]
Estimate: N h
Dependencies: all closed | [list of open blockers]
Acceptance Criteria: [checklist]
Spec Summary: [key requirements in 5-10 lines]
Key Files: [existing files to modify + new files to create]
Module Context: [summary from module AGENTS.md, or "new module"]
```

**Orchestrator actions** (after receiving the brief):
- If dependencies are open â€” STOP, ask user for decision
- Move issue to "In Progress" on the project board
- Add comment: "ðŸš€ Implementation started"

## Phase 1: Plan

Launch a **planner** subagent (`Task` tool, `subagent_type: planner`). Pass it:
- The task brief from Phase 0 (includes module context summary and key files)

The planner has Read access â€” it will read module AGENTS.md files and spec docs itself,
guided by the Key Files and Spec References in the brief.
Runs 3 rounds of self-verification (structure â†’ scope â†’ codebase fit)
and returns a step-by-step plan.

## Phase 1a: Verify Plan

Launch a **plan-verifier** subagent (`Task` tool, `subagent_type: plan-verifier`). Pass it:
- The plan from Phase 1
- Task description and acceptance criteria from the brief

The verifier checks: AC coverage, file path validity, TDD order, scope, conventions.
Returns PASS or FAIL with specific issues.

If **FAIL**: launch a new **planner** subagent with the original brief + current plan +
verifier issues. Planner revises the plan, then re-run plan-verifier. Max 2 cycles.

After PASS: present the plan to me and **STOP â€” wait for my approval**.
If planner flagged clarifications â€” relay them to me, do NOT proceed.

## Phase 2: Implement + Validate

After plan approval, launch an **implementer** subagent
(`Task` tool, `subagent_type: implementer`). Pass it:
- The approved plan (full text)
- Any clarifications or decisions from Phase 1 discussion

The implementer writes code following TDD using `bun test <file> --reporter=dots`
for minimal output. Returns a summary of changes (files created/modified, issues encountered).
The implementer does NOT run full validation â€” that's the validator's job.

After implementer completes, launch a **validator** subagent
(`Task` tool, `subagent_type: validator`).
It runs `bun test`, `bun run typecheck`, `bun run lint` and returns a structured report:
result (PASS/FAIL), test count, failure list with file:line (max 10 per section).

If validator returns **FAIL**:
- Launch the **implementer** subagent again with: the approved plan + validator failure output
- Re-run validator after fixes
- Maximum 3 fix cycles. If still failing, STOP and present failures to me

## Phase 3: Review

1. Move issue to "In Review" on the project board
2. Launch a **reviewer** subagent (`Task` tool, `subagent_type: reviewer`).
   Pass it: the plan and the task brief for context.
   The reviewer returns a verdict: APPROVED / NEEDS_REVISION / FAILED

If verdict is **NEEDS_REVISION**:
- Launch the **implementer** subagent with: the approved plan + review feedback
- Re-run validator
- Re-run reviewer
- Maximum 3 revision cycles. If still not APPROVED, STOP
  and present all unresolved issues to me

If verdict is **FAILED**:
- STOP and present the failure to me

If verdict is **APPROVED**:
- Proceed to Phase 4

## Phase 4: Close Task

Launch a **general-purpose** subagent (`Task` tool, `subagent_type: general-purpose`).
Pass it: task brief, approved plan, change summary from implementer, review verdict,
and list of deviations (what changed vs plan). Instruct it to:

1. **Update issue with deviations** â€” edit the GitHub issue description, appending:
   ```
   ### Deviations
   - [what changed vs original plan and why]
   - [anything discovered during implementation]
   - [scope added/removed with reason]
   ```
   If no deviations â€” append `### Deviations\nNone.`
2. Add closing comment: verdict + files changed + test count
3. Move issue to "Done" on the project board
4. Update AGENTS.md â€” "Current Sprint" section:
   - Move task from "In progress" / "Next" to "Completed"
   - Update "Next" with the next unblocked task (check dependencies)
5. **Update module AGENTS.md** â€” for each module directory touched by this task:
   - If `AGENTS.md` doesn't exist â€” create it (see template in root AGENTS.md)
   - If it exists â€” update Key Files, Interfaces, Patterns sections to reflect changes
   - Update the Module Documentation table in root AGENTS.md if a new module was added

The subagent returns a suggested conventional commit message referencing the issue
(e.g., `feat(db): add schema and migrations closes #42`).

Present the commit message and the execution summary to me. STOP and wait for me to commit.

## Execution Summary

After Phase 4 completes, present this summary:

```
## Execution Summary: TASK-X.Y

### Subagent Invocations
| Subagent        | Invocations | Reason for re-runs             |
|-----------------|:-----------:|--------------------------------|
| context-loader  | 1           | â€”                              |
| planner         | N           | [verifier FAIL Ã— (N-1)]        |
| plan-verifier   | N           | [planner revisions Ã— (N-1)]    |
| implementer     | N           | [validator FAIL Ã— A, review Ã— B] |
| validator       | N           | [impl fix Ã— A, review fix Ã— B]  |
| reviewer        | N           | [revision Ã— (N-1)]             |
| close-task      | 1           | â€”                              |
| **Total**       | **N**       |                                |

### Tool Issues
- [tool name] â€” [what failed and why] (or "None")

### Stops
- Plan approval: [user approved / user modified plan / N clarification rounds]
- Failures: [none / list of phases where STOP was triggered]
```

Track these counters throughout execution. Increment each time a subagent is launched.
If a subagent reports a tool permission denial or unavailable tool, record it.

## Context Management

All heavy work runs in subagents to protect the main context window:
- **general-purpose** (Phase 0) â€” reads issue, backlog, specs; enriches issue; returns task brief
- **planner** â€” reads specs + codebase, produces plan with 3-round self-verification
- **plan-verifier** â€” checks plan against AC, file paths, TDD order, conventions
- **implementer** â€” writes code following TDD with `--reporter=dots` for minimal output
- **validator** â€” runs test/typecheck/lint, returns structured PASS/FAIL report
- **reviewer** â€” reads git diff, evaluates correctness/quality/security, returns verdict
- **general-purpose** (Phase 4) â€” updates GitHub issue, AGENTS.md, module AGENTS.md; returns commit message

The main orchestrator only sees: task brief, plan, verification result, change summary,
validation report, review verdict, commit message.

**Rules for subagent context:**
- Pass full context INTO subagents explicitly â€” they do not inherit conversation history
- Always pass the approved plan to implementer (including in revision loops)
- In loops, pass only the LATEST failure/review output â€” not the full history

## Rules

- ALWAYS check dependencies before starting â€” never implement against open blockers
- Follow TDD strictly: test first, then implementation, then verification
- Do NOT modify files outside the plan scope â€” if you discover adjacent work needed,
  flag it as a follow-up, do not fix it
- If implementer hits a blocker after 3 attempts at any step, STOP and explain â€”
  do not loop endlessly
- Present commit message at the end. NEVER run git add/commit/push yourself
- If the task turns out larger than expected mid-implementation, STOP and discuss
  splitting it with me rather than continuing with a bloated PR
