# =============================================================================
# Mema — Environment Variables
# =============================================================================
# Copy to .env and fill in actual values.
# LLM model variables are read on each call — swappable without restart.

# --- Application ---
NODE_ENV=development
PORT=3000

# --- Database (PostgreSQL + pgvector) ---
# Use "localhost" for local development, "db" for Docker Compose
DATABASE_URL=postgresql://mema:password@localhost:5432/mema

# Docker Compose PostgreSQL credentials
POSTGRES_DB=mema
POSTGRES_USER=mema
POSTGRES_PASSWORD=password

# --- Telegram ---
TELEGRAM_BOT_TOKEN=your-telegram-bot-token
TELEGRAM_WEBHOOK_URL=https://your-domain.com/webhook

# --- LLM Providers ---
OPENAI_API_KEY=your-openai-api-key
ANTHROPIC_API_KEY=your-anthropic-api-key

# --- LLM Models (swappable without restart) ---
LLM_COMPACT_MODEL=gpt-5-nano
LLM_POWERFUL_MODEL_A=claude-opus-4-6
LLM_POWERFUL_MODEL_B=gpt-5.2
LLM_VALIDATOR_MODEL=gpt-5-nano
LLM_EMBEDDING_MODEL=text-embedding-3-small

# --- Administration ---
ADMIN_USER_ID=your-telegram-user-id

# --- Sentry (Error Monitoring) ---
SENTRY_DSN=your-sentry-dsn

# --- Rate Limiting ---
RATE_LIMIT_PER_HOUR=100

# --- Token Quota ---
# Monthly token limit per user (value TBD after launch)
TOKEN_QUOTA_MONTHLY=0
